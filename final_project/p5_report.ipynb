{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Identify Fraud from Enron Email\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 1.\tSummarize for us the goal of this project and how machine learning is useful in trying to accomplish it. As part of your answer, give some background on the dataset and how it can be used to answer the project question. Were there any outliers in the data when you got it, and how did you handle those?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The Enron dataset is a email dataset that contains emails associated with more than 100 senior management staff of Enron Corporation, which filed bankrupcy in December 2001.  The goal of this project is to predict persons of interest in the dataset based on their financial and email features.\n",
    "\n",
    "The financial features includes salary, deferral_payments, total_payments, loan_advances, bonus, restricted_stock_deferred, deferred_income, total_stock_value, expenses, exercised_stock_options, long_term_incentives, restricted_stock, director_fees, and other.\n",
    "\n",
    "The email features include to_messages, from_poi_to_this_person, from_messages, from_this_person_to_poi, and shared_receipt_with_poi.\n",
    "\n",
    "I found there is an outlier in the dataset when looking at the salary and bonus data.  This record includes the total salary and total bonus of all the staff in the dataset.  I removed this record named \"TOTAL\".\n",
    "\n",
    "There is another record that has missing values for every feature.  I deleted this record named \"LOCKHART EUGENE E\".\n",
    "\n",
    "There is a third record that is not for a person, but rather it is for \"THE TRAVEL AGENCY IN THE PARK\".  It was deleted.\n",
    "\n",
    "There is a total of 146 records in the dataset.  There are 18 person of interest (poi) and 128 none-poi.  After deleting the two outliers, there are 143 records left.\n",
    "\n",
    "Of all the features, only poi has no missing value.  All the others have missing values.  For example, salary has 49 missing values, and to_message has 57 missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 2.\tWhat features did you end up using in your POI identifier, and what selection process did you use to pick them? Did you have to do any scaling? Why or why not? As part of the assignment, you should attempt to engineer your own feature that does not come ready-made in the dataset -- explain what feature you tried to make, and the rationale behind it. (You do not necessarily have to use it in the final analysis, only engineer and test it.) In your feature selection step, if you used an algorithm like a decision tree, please also give the feature importances of the features that you use, and if you used an automated feature selection function like SelectKBest, please report the feature scores and reasons for your choice of parameter values.\n",
    "I creatd two new features.  On is the ratio of messages that were sent to poi to the total messages that were sent out.  The other is the ratio of messages that were received from poi to the total messages that were received.  I used SelectKBest to evaluate the features and selected the top five.  They are exercised_stock_options, total_stock_value, bonus, salary, and deferred_income."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 3.\tWhat algorithm did you end up using? What other one(s) did you try? How did model performance differ between algorithms?\n",
    "I tried naive bayes, SVM, decision tree, and logistic regression algorithms.  The best one is naive bayes.  The model accuracy is 0.68, precision is 0.17, and recll is 0.33."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 4.\tWhat does it mean to tune the parameters of an algorithm, and what can happen if you don’t do this well?  How did you tune the parameters of your particular algorithm? (Some algorithms do not have parameters that you need to tune -- if this is the case for the one you picked, identify and briefly explain how you would have done it for the model that was not your final choice or a different model that does utilize parameter tuning, e.g. a decision tree classifier).\n",
    "Parameter tunning is to look for the best parameter that can fit the test records.  Over tunning can over fit the test features and therefore makes the prediction model biased.  As a result, although tuned parameters may work well for the training dataset, but it can fail for the test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 5.\tWhat is validation, and what’s a classic mistake you can make if you do it wrong? How did you validate your analysis?\n",
    "The validation process is used to determine if the selected algorithm is generalized.  I split the dataset in order to validate the algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 6.\tGive at least 2 evaluation metrics and your average performance for each of them.  Explain an interpretation of your metrics that says something human-understandable about your algorithm’s performance.\n",
    "I used accuracy, precision, and recall as the evaluation metrics.  The model naive bayse accuracy is 0.68, precision is 0.17, and recll is 0.33."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### References\n",
    "\n",
    "1. https://en.wikipedia.org/wiki/Enron\n",
    "2. https://en.wikipedia.org/wiki/Enron_scandal\n",
    "3. http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html\n",
    "4. https://www.cs.cmu.edu/~./enron/\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
